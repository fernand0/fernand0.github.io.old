---
layout: post
title: "Los robots que navegan por la web y nuestra privacidad"
date: "2021-07-19 15:00:00 +0000"
category: privacidad
tags:
- privacidad
- seguridad
- internet
- datos
- demoscopía
imagefeature: 'http://live.staticflickr.com/4882/32271235718_db28c056d3.jpg'
---
<a href="https://www.flickr.com/photos/fernand0/32271235718/" title="Telégrafos "><img src="http://live.staticflickr.com/4882/32271235718_db28c056d3.jpg" alt="Telégrafos " width="240" style="float:left; margin:5px"></a>
En [Extracting Personal Information from Large Language Models Like GPT-2](https://www.schneier.com/blog/archives/2021/01/extracting-personal-information-from-large-language-models-like-gpt-2.html) un recordatorio de que todo lo que ponemos en internet puede ser leído por alguien y, en consecuencia, no podemos contar con que no se sabrá.

Se refiere al [modelo GPT-2](https://www.schneier.com/blog/archives/2021/01/extracting-personal-information-from-large-language-models-like-gpt-2.html) que trata de generar párrafos de texto coherentes entrenando a una inteligencia artificial con datos obtenidos de internet.

> We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text,  ...

Cuando se usan esas cantidades de datos es difícil validar todo lo que hay allí y, por lo tanto, a veces se utilizan datos que pueden tener información que algunas personas considerarían delicada.

> These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data.

La privacidad dejó de existir hace algún tiempo y este estudio es una pieza más en la demostración. Podemos pensar en prohibir, censurar,... Pero siempre habrá alguien con capacidad de hacerlo y mostrarlo (como es el caso) o pasar desapercibido porque nadie pueda mirarlo.
